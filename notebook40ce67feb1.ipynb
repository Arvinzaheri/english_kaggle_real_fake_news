{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WkKAXYq-Fhp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'real-and-fake-news-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F402856%2F772680%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240312%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240312T111747Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dc3227465d383492a68ffacb6962a1b711cd9e47e0bb3aefd61f40805e4bc1759a97ff81b22a5634a0b92c6f5da132d61130244f28b0f2eb2d529ebc88b470acfb2a743f6e4cee30f1be66b61e919f6b920e006d2c1959fc91e9324fb04a8d39cb497cad182d45f0d9b8698988521a6f01641b84b05b72373fb5feae6f97f018506b394e200a2b2f36ad09a4e1dc78e475018e0dee3c0e02b5467cda309f491555d64c93e1f959bdeeb47fca25bd159f8873a0145df4583397816977b048ee99f5b2f090c5af0ebbca30e7f8d6a7daeccc9611983722e120e811ee4b2eea56d72ae408284e0e8e2ae358bb6130273e0b09489df4ad3e26021fe69800d2a2bfa8e'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "G3tXArf0-Fhq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "FVzBKxze-Fhr",
        "outputId": "dcd37dbc-23cb-4747-d79c-f274b1b41150"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8476</td>\n",
              "      <td>You Can Smell Hillary’s Fear</td>\n",
              "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10294</td>\n",
              "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
              "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3608</td>\n",
              "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
              "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10142</td>\n",
              "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
              "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>875</td>\n",
              "      <td>The Battle of New York: Why This Primary Matters</td>\n",
              "      <td>It's primary day in New York and front-runners...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                              title  \\\n",
              "0        8476                       You Can Smell Hillary’s Fear   \n",
              "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
              "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
              "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
              "4         875   The Battle of New York: Why This Primary Matters   \n",
              "\n",
              "                                                text label  \n",
              "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
              "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
              "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
              "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
              "4  It's primary day in New York and front-runners...  REAL  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "data = pd.read_csv('news.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "013L4Xs4-fIY",
        "outputId": "0e2322d7-9d7d-492c-8bfb-4671a9b76e8d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title label\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "data.groupby('label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)\n",
        "#looks like we have a balanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu08lB3F-Tdg",
        "outputId": "ecb109ec-a7c3-47ce-c8ef-9889063f6568"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6335, 4)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnQMJFXb_a3g",
        "outputId": "0b24f15c-bf12-41eb-8b6c-d978c27912e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6256"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"title\"].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "W6-XOhX2A76N"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y_label = encoder.fit_transform(data[\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Assuming y_label is the original label data\n",
        "y_label_encoded = to_categorical(y_label, num_classes=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGrtYBzpNm7b",
        "outputId": "7e836960-d14a-495a-d815-0a290dac11ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Arvin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Arvin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove Stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iKF07xglOV5w"
      },
      "outputs": [],
      "source": [
        "data[\"title\"] = data[\"title\"].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "l0zfKjkV-ZCp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, GRU, Dropout, Bidirectional, SpatialDropout1D, Conv1D, BatchNormalization, Input, AveragePooling1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "q6I9_-sg-_Hi"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(\n",
        "    num_words=None,\n",
        "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n1234567890',\n",
        "    lower=True,\n",
        "    split=' ',\n",
        "    char_level=False,\n",
        "    oov_token=\"<oov>\",\n",
        "    analyzer=None,\n",
        ")\n",
        "title = data[\"title\"]\n",
        "tokenizer.fit_on_texts(title)\n",
        "X_title = tokenizer.texts_to_sequences(title)\n",
        "X_title_paded = pad_sequences(X_title, maxlen=100, dtype='int32', padding='pre', truncating='post', value=0.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7457"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "zewrwHW6BF0O"
      },
      "outputs": [],
      "source": [
        "def model_gen(pre_trained_embd, pre_trained_embd_layer, embedding_input, embedding_output, lstm_layers, lstm_units, dense_layers, dense_units, output_classes, input_length, conv_layers, conv_units):\n",
        "    if not pre_trained_embd:\n",
        "        input = Input(shape=(input_length,))\n",
        "        x = Embedding(embedding_input, embedding_output)(input)\n",
        "        # Add SpatialDropout1D layer\n",
        "        x = SpatialDropout1D(0.3)(x)\n",
        "    else:\n",
        "        input = Input(shape=(), dtype=tf.string)\n",
        "        x = pre_trained_embd_layer(input)\n",
        "    \n",
        "    \n",
        "    # Add Conv1D layers based on the input parameters\n",
        "    for i in range(conv_layers):\n",
        "        x = Conv1D(filters=conv_units, kernel_size=4, padding='same', activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = AveragePooling1D(pool_size=2)(x)\n",
        "    \n",
        "    # Add LSTM layers and dropout based on the input parameters\n",
        "    for i in range(lstm_layers):\n",
        "        x = Bidirectional(LSTM(lstm_units, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "    \n",
        "    x = Bidirectional(GRU(32, dropout=0.6, recurrent_dropout=0.5))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Bidirectional(GRU(16, dropout=0.5, recurrent_dropout=0.5))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    # Add Dense layers, dropout and batch normalization based on the input parameters\n",
        "    for i in range(dense_layers):\n",
        "        x = Dense(dense_units, activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.6)(x)\n",
        "    \n",
        "    output = Dense(output_classes, activation='sigmoid')(x)\n",
        "    \n",
        "    model = Model(inputs=input, outputs=output)\n",
        "    return model\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 100, 64)           477248    \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 100, 64)           0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 100, 32)           8224      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 100, 32)           128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " average_pooling1d (Average  (None, 50, 32)            0         \n",
            " Pooling1D)                                                      \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 50, 128)           49664     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 50, 128)           512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 64)                31104     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 64)                256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                2080      \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 32)                128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 569410 (2.17 MB)\n",
            "Trainable params: 568898 (2.17 MB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()\n",
        "#Define the model and compiling \n",
        "model_with_title = model_gen(\n",
        "    embedding_input=vocab_size, \n",
        "    embedding_output=64, \n",
        "    lstm_layers=1, \n",
        "    lstm_units=32, \n",
        "    dense_layers=1, \n",
        "    dense_units=32, \n",
        "    output_classes=2, \n",
        "    input_length=100, \n",
        "    conv_layers=1, \n",
        "    conv_units=32)\n",
        "\n",
        "model_with_title.compile(optimizer=Adam(learning_rate=0.0004), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_with_title.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "# Define the learning rate schedule function\n",
        "def lr_schedule(epoch, lr):\n",
        "    if epoch < 2:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * np.exp(-0.1)\n",
        "    \n",
        "# Create the LearningRateScheduler callback\n",
        "lr_scheduler = LearningRateScheduler(schedule=lr_schedule, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "84/84 [==============================] - 39s 229ms/step - loss: 1.0395 - accuracy: 0.5052 - val_loss: 0.7187 - val_accuracy: 0.4763\n",
            "Epoch 2/20\n",
            "84/84 [==============================] - 20s 245ms/step - loss: 0.9409 - accuracy: 0.5215 - val_loss: 0.7523 - val_accuracy: 0.4763\n",
            "Epoch 3/20\n",
            "84/84 [==============================] - 20s 240ms/step - loss: 0.8443 - accuracy: 0.5640 - val_loss: 0.7320 - val_accuracy: 0.4763\n",
            "Epoch 4/20\n",
            "84/84 [==============================] - 21s 245ms/step - loss: 0.7160 - accuracy: 0.6659 - val_loss: 0.6549 - val_accuracy: 0.5710\n",
            "Epoch 5/20\n",
            "84/84 [==============================] - 21s 251ms/step - loss: 0.5811 - accuracy: 0.7559 - val_loss: 0.5034 - val_accuracy: 0.7692\n",
            "Epoch 6/20\n",
            "84/84 [==============================] - 24s 284ms/step - loss: 0.4535 - accuracy: 0.8295 - val_loss: 0.4426 - val_accuracy: 0.7939\n",
            "Epoch 7/20\n",
            "84/84 [==============================] - 24s 280ms/step - loss: 0.3555 - accuracy: 0.8833 - val_loss: 0.4857 - val_accuracy: 0.7998\n",
            "Epoch 8/20\n",
            "84/84 [==============================] - 25s 293ms/step - loss: 0.2808 - accuracy: 0.9049 - val_loss: 0.5085 - val_accuracy: 0.8097\n",
            "Epoch 9/20\n",
            "84/84 [==============================] - 22s 264ms/step - loss: 0.2203 - accuracy: 0.9320 - val_loss: 0.6096 - val_accuracy: 0.8057\n",
            "Epoch 10/20\n",
            "84/84 [==============================] - 22s 262ms/step - loss: 0.1846 - accuracy: 0.9442 - val_loss: 0.6200 - val_accuracy: 0.8126\n",
            "Epoch 11/20\n",
            "84/84 [==============================] - 25s 297ms/step - loss: 0.1638 - accuracy: 0.9556 - val_loss: 0.6699 - val_accuracy: 0.8037\n",
            "Epoch 12/20\n",
            "84/84 [==============================] - 24s 285ms/step - loss: 0.1324 - accuracy: 0.9600 - val_loss: 0.7189 - val_accuracy: 0.8077\n",
            "Epoch 13/20\n",
            "84/84 [==============================] - 21s 248ms/step - loss: 0.1263 - accuracy: 0.9634 - val_loss: 0.7019 - val_accuracy: 0.8116\n",
            "Epoch 14/20\n",
            "84/84 [==============================] - 22s 259ms/step - loss: 0.1087 - accuracy: 0.9669 - val_loss: 0.7519 - val_accuracy: 0.8067\n",
            "Epoch 15/20\n",
            "84/84 [==============================] - 21s 252ms/step - loss: 0.1018 - accuracy: 0.9737 - val_loss: 0.8099 - val_accuracy: 0.8018\n",
            "Epoch 16/20\n",
            "84/84 [==============================] - 23s 269ms/step - loss: 0.0871 - accuracy: 0.9744 - val_loss: 0.8302 - val_accuracy: 0.8057\n",
            "Epoch 17/20\n",
            "84/84 [==============================] - 25s 298ms/step - loss: 0.0828 - accuracy: 0.9776 - val_loss: 0.8458 - val_accuracy: 0.8057\n",
            "Epoch 18/20\n",
            "84/84 [==============================] - 24s 282ms/step - loss: 0.0642 - accuracy: 0.9825 - val_loss: 0.8403 - val_accuracy: 0.8087\n",
            "Epoch 19/20\n",
            "84/84 [==============================] - 25s 297ms/step - loss: 0.0597 - accuracy: 0.9840 - val_loss: 0.8950 - val_accuracy: 0.8057\n",
            "Epoch 20/20\n",
            "84/84 [==============================] - 25s 301ms/step - loss: 0.0525 - accuracy: 0.9865 - val_loss: 0.9039 - val_accuracy: 0.8067\n"
          ]
        }
      ],
      "source": [
        "#Now we fit the model\n",
        "history = model_with_title.fit(X_title_paded, y_label_encoded, epochs=20, batch_size=64, validation_split=0.16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we tried diffrent model architecture and it did not improve the accuracy\n",
        "in the next step i try to use a pretrained embedding and see if i can improve the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install tensorflow-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Arvin\\quera1\\qenv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Arvin\\quera1\\qenv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Arvin\\quera1\\qenv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Arvin\\quera1\\qenv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the ELMo module from TensorFlow Hub\n",
        "#!pip install tensorflow_hub\n",
        "import tensorflow_hub as hub\n",
        "elmo = hub.KerasLayer(\"https://tfhub.dev/google/elmo/3\", trainable=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None,) dtype=string (created by layer 'input_7')>"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Exception encountered when calling layer 'keras_layer' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `too many positional arguments`. Received args: ('you can smell hillari ’ fear',) and kwargs: {} for signature: () -> Dict[['lstm_outputs1', TensorSpec(shape=(None, None, 1024), dtype=tf.float32, name=None)], ['lstm_outputs2', TensorSpec(shape=(None, None, 1024), dtype=tf.float32, name=None)], ['word_emb', TensorSpec(shape=(None, None, 512), dtype=tf.float32, name=None)], ['elmo', TensorSpec(shape=(None, None, 1024), dtype=tf.float32, name=None)], ['sequence_len', TensorSpec(shape=(None,), dtype=tf.int32, name=None)], ['default', TensorSpec(shape=(None, 1024), dtype=tf.float32, name=None)]].\nFallback to flat signature also failed due to: pruned(text): expected argument #0(zero-based) to be a Tensor; got str (you can smell hillari ’ fear).\n\nCall arguments received by layer 'keras_layer' (type KerasLayer):\n  • inputs='you can smell hillari ’ fear'\n  • training=None",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[147], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43melmo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
            "File \u001b[1;32mc:\\Users\\Arvin\\quera1\\qenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\Arvin\\quera1\\qenv\\Lib\\site-packages\\tensorflow_hub\\keras_layer.py:242\u001b[0m, in \u001b[0;36mKerasLayer.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# ...but we may also have to pass a Python boolean for `training`, which\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# is the logical \"and\" of this layer's trainability and what the surrounding\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# model is doing (analogous to keras.layers.BatchNormalization in TF2).\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# For the latter, we have to look in two places: the `training` argument,\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_training_argument:\n\u001b[1;32m--> 242\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable:\n",
            "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling layer 'keras_layer' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `too many positional arguments`. Received args: ('you can smell hillari ’ fear',) and kwargs: {} for signature: () -> Dict[['lstm_outputs1', TensorSpec(shape=(None, None, 1024), dtype=tf.float32, name=None)], ['lstm_outputs2', TensorSpec(shape=(None, None, 1024), dtype=tf.float32, name=None)], ['word_emb', TensorSpec(shape=(None, None, 512), dtype=tf.float32, name=None)], ['elmo', TensorSpec(shape=(None, None, 1024), dtype=tf.float32, name=None)], ['sequence_len', TensorSpec(shape=(None,), dtype=tf.int32, name=None)], ['default', TensorSpec(shape=(None, 1024), dtype=tf.float32, name=None)]].\nFallback to flat signature also failed due to: pruned(text): expected argument #0(zero-based) to be a Tensor; got str (you can smell hillari ’ fear).\n\nCall arguments received by layer 'keras_layer' (type KerasLayer):\n  • inputs='you can smell hillari ’ fear'\n  • training=None"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Input 0 of layer \"conv1d_1\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 1024)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[157], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_with_title_v2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_trained_embd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_trained_embd_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melmo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlstm_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlstm_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdense_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdense_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconv_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconv_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m model_with_title_v2\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0004\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m model_with_title_v2\u001b[38;5;241m.\u001b[39msummary()\n",
            "Cell \u001b[1;32mIn[156], line 15\u001b[0m, in \u001b[0;36mmodel_gen\u001b[1;34m(pre_trained_embd, pre_trained_embd_layer, embedding_input, embedding_output, lstm_layers, lstm_units, dense_layers, dense_units, output_classes, input_length, conv_layers, conv_units)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Add Conv1D layers based on the input parameters\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(conv_layers):\n\u001b[1;32m---> 15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m BatchNormalization()(x)\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m AveragePooling1D(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)(x)\n",
            "File \u001b[1;32mc:\\Users\\Arvin\\quera1\\qenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\Arvin\\quera1\\qenv\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py:253\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"conv1d_1\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 1024)"
          ]
        }
      ],
      "source": [
        "model_with_title_v2 = model_gen(\n",
        "    pre_trained_embd=True,\n",
        "    pre_trained_embd_layer=elmo,\n",
        "    embedding_input=vocab_size, \n",
        "    embedding_output=64, \n",
        "    lstm_layers=1, \n",
        "    lstm_units=32, \n",
        "    dense_layers=1, \n",
        "    dense_units=32, \n",
        "    output_classes=2, \n",
        "    input_length=100, \n",
        "    conv_layers=1, \n",
        "    conv_units=32\n",
        ")\n",
        "\n",
        "model_with_title_v2.compile(optimizer=Adam(learning_rate=0.0004), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_with_title_v2.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "notebook40ce67feb1",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 402856,
          "sourceId": 772680,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "qenv",
      "language": "python",
      "name": "qenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
